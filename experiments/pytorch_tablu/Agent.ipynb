{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "Author: Zhen Liu lzhen.dev@outlook.com\n",
    "CreateDate: Do not edit\n",
    "LastEditors: Zhen Liu lzhen.dev@outlook.com\n",
    "LastEditTime: 2024-03-02\n",
    "Description: \n",
    "\n",
    "Copyright (c) 2024 by HernandoR lzhen.dev@outlook.com, All Rights Reserved. \n",
    "'''\n",
    "import torch\n",
    "from sklearn.datasets import make_classification\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, f1_score\n",
    "import random\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import wandb\n",
    "\n",
    "from typing import Callable\n",
    "from datetime import datetime\n",
    "\n",
    "\n",
    "from pytorch_tabular.utils import make_mixed_dataset, print_metrics, load_covertype_dataset\n",
    "from pytorch_tabular.utils import get_balanced_sampler, get_class_weighted_cross_entropy\n",
    "\n",
    "import os\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# wandb.login()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "# data, cat_col_names, num_col_names = make_mixed_dataset(\n",
    "#     task=\"classification\", \n",
    "#     n_samples=10000, \n",
    "#     n_features=8, \n",
    "#     n_categories=4, \n",
    "#     weights=[0.8], \n",
    "#     random_state=42)\n",
    "# target_col='target'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gpu\n"
     ]
    }
   ],
   "source": [
    "\n",
    "Feature_Explain=pd.read_excel('data/Amex_ori/Amex Campus.xlsx')\n",
    "Feature_target_cols = Feature_Explain['Feature Name'][Feature_Explain['Extended description']=='Target'].to_list()\n",
    "Feature_cat_col_names = Feature_Explain['Feature Name'][Feature_Explain['Feature Type']=='categorical'].to_list()\n",
    "Feature_num_col_names = Feature_Explain['Feature Name'][Feature_Explain['Variable Type'] =='numeric'].to_list()\n",
    "\n",
    "DEVICE=\"mps\" if torch.backends.mps.is_available() else ('gpu' if torch.cuda.is_available() else \"cpu\")\n",
    "print(DEVICE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_parquet('data/train.parquet')\n",
    "\n",
    "cols=data.columns.to_list()\n",
    "target_cols = [col for col in cols if col in Feature_target_cols]\n",
    "if len(target_cols) == 0:\n",
    "    print('No target column found')\n",
    "    exit()\n",
    "elif len(target_cols) > 1:\n",
    "    target_col=target_cols[1]\n",
    "cat_col_names = [col for col in cols if col in Feature_cat_col_names]\n",
    "num_col_names = [col for col in cols if col in Feature_num_col_names]\n",
    "\n",
    "print(f\"{target_cols}\")\n",
    "# target_col=cols.unite(Feature_target_cols)\n",
    "\n",
    "# target_col = 'activation'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "data.head()\n",
    "print(f\"target_col={target_col}, cat_col_names={cat_col_names}, num_col_names={num_col_names}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "train, test = train_test_split(data, random_state=42)\n",
    "train, val = train_test_split(train, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data['customer_digital_activity_01'].value_counts(normalize=True)\n",
    "# data.describe()\n",
    "# len(train)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "# Importing the Library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "from pytorch_tabular import TabularModel\n",
    "from pytorch_tabular.models import CategoryEmbeddingModelConfig\n",
    "from pytorch_tabular.config import DataConfig, OptimizerConfig, TrainerConfig, ExperimentConfig\n",
    "from pytorch_tabular.models.common.heads import LinearHeadConfig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = []"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "## Define the Configs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Windows does not support num_workers > 0. Setting num_workers to 0\n"
     ]
    }
   ],
   "source": [
    "data_config = DataConfig(\n",
    "    target=[target_col], \n",
    "    #target should always be a list. Multi-targets are only supported for regression. Multi-Task Classification is not implemented\n",
    "    continuous_cols=num_col_names,\n",
    "    categorical_cols=cat_col_names,\n",
    "    num_workers=5\n",
    ")\n",
    "trainer_config = TrainerConfig(\n",
    "    auto_lr_find=True, # Runs the LRFinder to automatically derive a learning rate\n",
    "    batch_size=5210,\n",
    "    max_epochs=100,\n",
    "    early_stopping=\"valid_loss\", # Monitor valid_loss for early stopping\n",
    "    early_stopping_mode = \"min\", # Set the mode as min because for val_loss, lower is better\n",
    "    early_stopping_patience=5, # No. of epochs of degradation training will wait before terminating\n",
    "    checkpoints=\"valid_loss\", # Save best checkpoint monitoring val_loss\n",
    "    checkpoints_path = 'checkpoints', # Save the checkpoint in the experiment directory\n",
    "    checkpoints_save_top_k = 5,\n",
    "    progress_bar='simple',\n",
    "    load_best=True, # After training, load the best checkpoint\n",
    "    accelerator=DEVICE,\n",
    "    trainer_kwargs={\n",
    "        \"enable_progress_bar\":True, \n",
    "        # \"max_steps\":1000,\n",
    "        # \"progress_bar_refresh_rate\":1\n",
    "    }\n",
    ")\n",
    "optimizer_config = OptimizerConfig()\n",
    "\n",
    "head_config = LinearHeadConfig(\n",
    "    layers=\"\", # No additional layer in head, just a mapping layer to output_dim\n",
    "    dropout=0.1,\n",
    "    initialization=\"kaiming\"\n",
    ").__dict__ # Convert to dict to pass to the model config (OmegaConf doesn't accept objects)\n",
    "\n",
    "EXP_PROJECT_NAME = \"AMEX\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "model_config = CategoryEmbeddingModelConfig(\n",
    "    task=\"classification\",\n",
    "    layers=\"1024-512-512\",  # Number of nodes in each layer\n",
    "    activation=\"LeakyReLU\", # Activation between each layers\n",
    "    head = \"LinearHead\", #Linear Head\n",
    "    head_config = head_config, # Linear Head Config\n",
    "    learning_rate = 1e-3,\n",
    "    metrics=[\"f1_score\",\"accuracy\"], \n",
    "    metrics_params=[{\"num_classes\":2},{}], # f1_score needs num_classes\n",
    "    metrics_prob_input=[True, False] # f1_score needs probability scores, while accuracy doesn't\n",
    ")\n",
    "\n",
    "experiment_config = ExperimentConfig(\n",
    "    project_name=EXP_PROJECT_NAME,\n",
    "    run_name=f\"{target_col}\",\n",
    "    exp_watch=\"gradients\",\n",
    "    # log_target=\"wandb\", # wandb will raise error, too many indicat for 1-d data.\n",
    "    # log_logits=True\n",
    ")\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "## Training the Model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false",
    "tags": []
   },
   "outputs": [],
   "source": [
    "tabular_model = TabularModel(\n",
    "    data_config=data_config,\n",
    "    model_config=model_config,\n",
    "    optimizer_config=optimizer_config,\n",
    "    trainer_config=trainer_config,\n",
    "    experiment_config=experiment_config,\n",
    "    verbose=False,\n",
    "    # suppress_lightning_logger=True,\n",
    "\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false",
    "scrolled": false,
    "tags": []
   },
   "outputs": [],
   "source": [
    "sampler = get_balanced_sampler(train[target_col].values.ravel())\n",
    "\n",
    "tabular_model.fit(train=train, validation=val, train_sampler=sampler)\n",
    "# takes ~ 60min,13 Epoch, most time in preparing data, weird"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = tabular_model.evaluate(test)\n",
    "# pred_df = tabular_model.predict(test)\n",
    "tabular_model.save_model(f\"{trainer_config.checkpoints_path}/{target_col}\") # save in the dir\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pred_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extractSubmision(input_df:pd.DataFrame,\n",
    "                     pred_col: str,\n",
    "                     cm_key='customer',\n",
    "                     mct_key='merchant',\n",
    "                     output_path='submission.csv')->None:\n",
    "    '''\n",
    "    function that extracts the submission file for the AMEX Singapore Hackathon 2024\n",
    "\n",
    "    input_df : pandas Dataframe which has customer, merchant and pred_col\n",
    "    pred_col : name of your prediction score variable\n",
    "    cm_key : customer unique ID (do not change)\n",
    "    mct_key : merchant unique ID (do not change)\n",
    "    output_path : path to save the submission file\n",
    "\n",
    "    Returns - None\n",
    "    '''\n",
    "    print('formate prodiction')\n",
    "    LEN=len(input_df)\n",
    "    if LEN!=12604600:\n",
    "        raise f\"miss matchlenth {LEN} \"\n",
    "    output_df=pd.DataFrame()\n",
    "    output_df[[cm_key,mct_key,'predicted_score']]=input_df[[cm_key,mct_key,pred_col]].apply(pd.to_numeric,errors='coerce')\n",
    "    output_df.to_csv(output_path,index=False)\n",
    "    return output_df\n",
    "\n",
    "def calc(rec:int,act:int):\n",
    "    crit=rec*2+act\n",
    "    match crit:\n",
    "        case 3: # TT\n",
    "            return 3\n",
    "        case 0: # NN\n",
    "            return 2\n",
    "        case 2: # TN\n",
    "            return 1\n",
    "        case 1: # NT\n",
    "            return 0\n",
    "    return None\n",
    "        \n",
    "# add colum pre_score by func calc eat 'ind_recommended' and 'activaton'\n",
    "        \n",
    "def loadmodel_and_predict(modelpath:str,test_data:pd.DataFrame,data_preprocess:Callable = None) -> pd.DataFrame:\n",
    "    print(f\"loading model at {modelpath}\")\n",
    "    loadedmodel=TabularModel.load_model(modelpath)\n",
    "    # idf=pd.read_csv(test_path)\n",
    "    if data_preprocess:\n",
    "        test_data=data_preprocess(test_data)\n",
    "    print(f\"predicting\")\n",
    "    return loadedmodel.predict(test_data)['prediction']\n",
    "\n",
    "def gen_submission(pred_df:pd.DataFrame):\n",
    "    print(\"generating_pred_score\")\n",
    "    for pred in [\"ind_recommended\",\"activation\",'customer','merchant']:\n",
    "        if pred not in pred_df.columns:\n",
    "            print(f\"missing col {pred}\")\n",
    "\n",
    "\n",
    "    pred_df['predicted_score']=pred_df.apply(lambda x:calc(x['ind_recommended'],x['activation']),axis=1)\n",
    "\n",
    "    \n",
    "    return extractSubmision(pred_df,'predicted_score')\n",
    "\n",
    "def preprocess(idf: pd.DataFrame):\n",
    "    cols=[]\n",
    "    for col in idf.columns:\n",
    "        if (col not in cat_col_names) and (col not in num_col_names):\n",
    "            cols.append(col)\n",
    "    idf.drop(columns=cols)\n",
    "    return idf\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "idf=pd.read_csv('data/Amex_ori/Amex Campus Challenge Round 1.csv')\n",
    "idf.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "for target in target_cols:\n",
    "    idf[target]=loadmodel_and_predict(f\"{trainer_config.checkpoints_path}/{target}\",idf,preprocess)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "idf=gen_submission(idf)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def incr_act_top10(input_df: pd.DataFrame,\n",
    "                   pred_col: str,\n",
    "                   cm_key='customer',\n",
    "                   treated_col='ind_recommended',\n",
    "                   actual_col='activation'):\n",
    "    '''\n",
    "    Function that returns the incremental activation score for the AMEX Singapore Hackathon 2024\n",
    "\n",
    "    input_df : pandas Dataframe which has customer, ind_recommended, activation and pred_col\n",
    "    pred_col : name of your prediction score variable\n",
    "    cm_key : customer unique ID (do not change)\n",
    "    treated_col : indicator variable whether a merchant was recommended\n",
    "    actual_col : whether a CM had transacted at a given merchant (target variable)\n",
    "\n",
    "    Returns - incremental activation\n",
    "    '''\n",
    "    \n",
    "\t#for correcting variable types\n",
    "    input_df[[treated_col, actual_col, pred_col]] = input_df[[treated_col, actual_col, pred_col]].apply(pd.to_numeric, errors='coerce')\n",
    "\t\n",
    "    input_df['rank_per_cm1'] = input_df.groupby(cm_key)[pred_col].rank(method='first', ascending=False)\n",
    "    \n",
    "    input_df = input_df.loc[input_df.rank_per_cm1 <= 10,:]\n",
    "    \n",
    "    agg_df = input_df.groupby(treated_col,as_index=False).agg({actual_col:'mean'})\n",
    "    agg_df.columns = [treated_col,'avg_30d_act']\n",
    "    \n",
    "    print(agg_df)\n",
    "    recommended_avg_30d_act = float(agg_df.iloc[agg_df[treated_col]==1,'avg_30d_act'])\n",
    "    not_recommended_avg_30d_act = float(agg_df.iloc[agg_df[treated_col]==0,'avg_30d_act'])\n",
    "    \n",
    "\t\n",
    "    return (recommended_avg_30d_act-not_recommended_avg_30d_act)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "idf=pd.read_parquet('data/Amex_ori/Amex Campus Challenge Train 3.parquet')\n",
    "bkp=pd.DataFrame()\n",
    "for target in target_cols:\n",
    "    bkp[target]=idf[target]\n",
    "    idf[target]=loadmodel_and_predict(f\"{trainer_config.checkpoints_path}/{target}\",idf,preprocess)\n",
    "idf=gen_submission(idf)\n",
    "\n",
    "for target in target_cols:\n",
    "    idf[target]=bkp[target]\n",
    "del bkp\n",
    "\n",
    "\n",
    "incr_act_top10(input_df = idf, pred_col = 'predicted_score')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Custom Sampler\n",
    "\n",
    "PyTorch Tabular also allows custom batching strategy through Custom Samplers  which comes in handy when working with imbalanced data.\n",
    "\n",
    "Although you can use any sampler, Pytorch Tabular has a few handy utility functions which takes in the target array and implements WeightedRandomSampler using inverse frequency sampling to combat imbalance. This is analogous to preprocessing techniques like Under or OverSampling in traditional ML systems."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tabular_model = TabularModel(\n",
    "    data_config=data_config,\n",
    "    model_config=model_config,\n",
    "    optimizer_config=optimizer_config,\n",
    "    trainer_config=trainer_config,\n",
    "    verbose=False\n",
    ")\n",
    "sampler = get_balanced_sampler(train[target_col].values.ravel())\n",
    "\n",
    "tabular_model.fit(train=train, validation=val, train_sampler=sampler)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = tabular_model.evaluate(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = {k: float(v) for k,v in result[0].items()}\n",
    "result[\"mode\"] = \"Balanced Sampler\"\n",
    "\n",
    "results.append(result)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Custom Weighted Loss\n",
    "\n",
    "If Samplers were like Over/Under Sampling, Custom Weighted Loss is similar to `class_weights`. Depending on the problem, one of these might help you with imbalance. You can easily make calculate the class_weights and provide them to the CrossEntropyLoss using the parameter `weight`. To make this easier, PyTorch Tabular has a handy utility method which calculates smoothed class weights and initializes a weighted loss. Once you have that loss, it's just a matter of passing it to the 1fit1 method using the `loss` parameter."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tabular_model = TabularModel(\n",
    "    data_config=data_config,\n",
    "    model_config=model_config,\n",
    "    optimizer_config=optimizer_config,\n",
    "    trainer_config=trainer_config,\n",
    "    verbose=False\n",
    ")\n",
    "weighted_loss = get_class_weighted_cross_entropy(train[\"target\"].values.ravel(), mu=0.1)\n",
    "\n",
    "tabular_model.fit(train=train, validation=val, loss=weighted_loss)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = tabular_model.evaluate(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = {k: float(v) for k,v in result[0].items()}\n",
    "result[\"mode\"] = \"Class Weights\"\n",
    "\n",
    "results.append(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res_df = pd.DataFrame(results).T\n",
    "res_df.columns = res_df.iloc[-1]\n",
    "res_df = res_df.iloc[:-1].astype(float)\n",
    "res_df.style.highlight_min(color=\"lightgreen\",axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
