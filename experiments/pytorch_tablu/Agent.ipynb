{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "'''\n",
    "Author: Zhen Liu lzhen.dev@outlook.com\n",
    "CreateDate: Do not edit\n",
    "LastEditors: Zhen Liu lzhen.dev@outlook.com\n",
    "LastEditTime: 2024-03-02\n",
    "Description: \n",
    "\n",
    "Copyright (c) 2024 by HernandoR lzhen.dev@outlook.com, All Rights Reserved. \n",
    "'''\n",
    "from sklearn.datasets import make_classification\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, f1_score\n",
    "import random\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import wandb\n",
    "\n",
    "from typing import Callable\n",
    "from datetime import datetime\n",
    "\n",
    "import torch\n",
    "\n",
    "from pytorch_tabular.utils import make_mixed_dataset, print_metrics, load_covertype_dataset\n",
    "from pytorch_tabular.utils import get_balanced_sampler, get_class_weighted_cross_entropy\n",
    "\n",
    "import os\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mhernando\u001b[0m (\u001b[33mlzhen-ntu\u001b[0m). Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wandb.login()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "# data, cat_col_names, num_col_names = make_mixed_dataset(\n",
    "#     task=\"classification\", \n",
    "#     n_samples=10000, \n",
    "#     n_features=8, \n",
    "#     n_categories=4, \n",
    "#     weights=[0.8], \n",
    "#     random_state=42)\n",
    "# target_col='target'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "Feature_Explain=pd.read_excel('data/Amex_ori/Amex Campus.xlsx')\n",
    "Feature_target_cols = Feature_Explain['Feature Name'][Feature_Explain['Extended description']=='Target'].to_list()\n",
    "Feature_cat_col_names = Feature_Explain['Feature Name'][Feature_Explain['Feature Type']=='categorical'].to_list()\n",
    "Feature_num_col_names = Feature_Explain['Feature Name'][Feature_Explain['Variable Type'] =='numeric'].to_list()\n",
    "\n",
    "DEVICE=\"mps\" if torch.backends.mps.is_available() else ('cuda' if torch.backends.cuda.is_available() else \"cpu\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['activation', 'ind_recommended']\n"
     ]
    }
   ],
   "source": [
    "data = pd.read_parquet('data/train.parquet')\n",
    "\n",
    "cols=data.columns.to_list()\n",
    "target_cols = [col for col in cols if col in Feature_target_cols]\n",
    "if len(target_cols) == 0:\n",
    "    print('No target column found')\n",
    "    exit()\n",
    "elif len(target_cols) > 1:\n",
    "    target_col=target_cols[0]\n",
    "cat_col_names = [col for col in cols if col in Feature_cat_col_names]\n",
    "num_col_names = [col for col in cols if col in Feature_num_col_names]\n",
    "\n",
    "print(f\"{target_cols}\")\n",
    "# target_col=cols.unite(Feature_target_cols)\n",
    "\n",
    "# target_col = 'activation'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "target_col=activation, cat_col_names=['merchant_profile_01'], num_col_names=['customer_digital_activity_02', 'customer_profile_01', 'customer_profile_02', 'customer_profile_03', 'customer_profile_04', 'customer_spend_06', 'customer_spend_07', 'distance_05']\n"
     ]
    }
   ],
   "source": [
    "\n",
    "data.head()\n",
    "print(f\"target_col={target_col}, cat_col_names={cat_col_names}, num_col_names={num_col_names}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "train, test = train_test_split(data, random_state=42)\n",
    "train, val = train_test_split(train, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data['customer_digital_activity_01'].value_counts(normalize=True)\n",
    "# data.describe()\n",
    "# len(train)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "# Importing the Library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "from pytorch_tabular import TabularModel\n",
    "from pytorch_tabular.models import CategoryEmbeddingModelConfig\n",
    "from pytorch_tabular.config import DataConfig, OptimizerConfig, TrainerConfig, ExperimentConfig\n",
    "from pytorch_tabular.models.common.heads import LinearHeadConfig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = []"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "## Define the Configs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "data_config = DataConfig(\n",
    "    target=[target_col], \n",
    "    #target should always be a list. Multi-targets are only supported for regression. Multi-Task Classification is not implemented\n",
    "    continuous_cols=num_col_names,\n",
    "    categorical_cols=cat_col_names,\n",
    "    num_workers=10\n",
    ")\n",
    "trainer_config = TrainerConfig(\n",
    "    auto_lr_find=True, # Runs the LRFinder to automatically derive a learning rate\n",
    "    batch_size=5210,\n",
    "    max_epochs=100,\n",
    "    early_stopping=\"valid_loss\", # Monitor valid_loss for early stopping\n",
    "    early_stopping_mode = \"min\", # Set the mode as min because for val_loss, lower is better\n",
    "    early_stopping_patience=5, # No. of epochs of degradation training will wait before terminating\n",
    "    checkpoints=\"valid_loss\", # Save best checkpoint monitoring val_loss\n",
    "    checkpoints_path = 'checkpoints', # Save the checkpoint in the experiment directory\n",
    "    checkpoints_save_top_k = 5,\n",
    "    progress_bar='simple',\n",
    "    load_best=True, # After training, load the best checkpoint\n",
    "    # accelerator=DEVICE,\n",
    "    trainer_kwargs={\n",
    "        \"enable_progress_bar\":True, \n",
    "        \"max_steps\":1000,\n",
    "        # \"progress_bar_refresh_rate\":1\n",
    "    }\n",
    ")\n",
    "optimizer_config = OptimizerConfig()\n",
    "\n",
    "head_config = LinearHeadConfig(\n",
    "    layers=\"\", # No additional layer in head, just a mapping layer to output_dim\n",
    "    dropout=0.1,\n",
    "    initialization=\"kaiming\"\n",
    ").__dict__ # Convert to dict to pass to the model config (OmegaConf doesn't accept objects)\n",
    "\n",
    "EXP_PROJECT_NAME = \"AMEX\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "model_config = CategoryEmbeddingModelConfig(\n",
    "    task=\"classification\",\n",
    "    layers=\"1024-512-512\",  # Number of nodes in each layer\n",
    "    activation=\"LeakyReLU\", # Activation between each layers\n",
    "    head = \"LinearHead\", #Linear Head\n",
    "    head_config = head_config, # Linear Head Config\n",
    "    learning_rate = 1e-3,\n",
    "    metrics=[\"f1_score\",\"accuracy\"], \n",
    "    metrics_params=[{\"num_classes\":2},{}], # f1_score needs num_classes\n",
    "    metrics_prob_input=[True, False] # f1_score needs probability scores, while accuracy doesn't\n",
    ")\n",
    "\n",
    "experiment_config = ExperimentConfig(\n",
    "    project_name=EXP_PROJECT_NAME,\n",
    "    run_name=f\"{target_col}\",\n",
    "    exp_watch=\"gradients\",\n",
    "    # log_target=\"wandb\", # wandb will raise error, too many indicat for 1-d data.\n",
    "    log_logits=True\n",
    ")\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "## Training the Model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "Collapsed": "false",
    "tags": []
   },
   "outputs": [],
   "source": [
    "tabular_model = TabularModel(\n",
    "    data_config=data_config,\n",
    "    model_config=model_config,\n",
    "    optimizer_config=optimizer_config,\n",
    "    trainer_config=trainer_config,\n",
    "    experiment_config=experiment_config,\n",
    "    verbose=False,\n",
    "    # suppress_lightning_logger=True,\n",
    "\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "Collapsed": "false",
    "scrolled": false,
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Seed set to 42\n",
      "GPU available: True (mps), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/AMEX/lib/python3.11/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:639: Checkpoint directory /Users/lz/Codes/AE2024/checkpoints exists and is not empty.\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/AMEX/lib/python3.11/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:436: Consider setting `persistent_workers=True` in 'train_dataloader' to speed up the dataloader worker initialization.\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/AMEX/lib/python3.11/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:436: Consider setting `persistent_workers=True` in 'val_dataloader' to speed up the dataloader worker initialization.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e62e9540e5d340e3b0bf5013bd071d9f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Finding best initial lr:   0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Trainer was signaled to stop but the required `min_epochs=1` or `min_steps=None` has not been met. Training will continue...\n",
      "`Trainer.fit` stopped: `max_steps=100` reached.\n",
      "Learning rate set to 0.0001\n",
      "Restoring states from the checkpoint path at /Users/lz/Codes/AE2024/.lr_find_9c8f10ef-3028-4a3e-8014-c75038d1b07e.ckpt\n",
      "Restored all states from the checkpoint at /Users/lz/Codes/AE2024/.lr_find_9c8f10ef-3028-4a3e-8014-c75038d1b07e.ckpt\n",
      "\n",
      "  | Name             | Type                      | Params\n",
      "---------------------------------------------------------------\n",
      "0 | _backbone        | CategoryEmbeddingBackbone | 833 K \n",
      "1 | _embedding_layer | Embedding1dLayer          | 2.6 K \n",
      "2 | head             | LinearHead                | 1.0 K \n",
      "3 | loss             | CrossEntropyLoss          | 0     \n",
      "---------------------------------------------------------------\n",
      "837 K     Trainable params\n",
      "0         Non-trainable params\n",
      "837 K     Total params\n",
      "3.349     Total estimated model params size (MB)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dcd0cb9199954edd819c20815ce41d5f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9241fa8a445e44eda8d2cd59f257b885",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_steps=1000` reached.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<pytorch_lightning.trainer.trainer.Trainer at 0x3597db790>"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sampler = get_balanced_sampler(train[target_col].values.ravel())\n",
    "\n",
    "tabular_model.fit(train=train, validation=val, train_sampler=sampler)\n",
    "# takes ~ 60min,13 Epoch, most time in preparing data, weird"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/Caskroom/miniforge/base/envs/AMEX/lib/python3.11/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:436: Consider setting `persistent_workers=True` in 'test_dataloader' to speed up the dataloader worker initialization.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e83180d967414e168c41ccbcc3eb7689",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\">        Test metric        </span>┃<span style=\"font-weight: bold\">       DataLoader 0        </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">       test_accuracy       </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.7198559641838074     </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">       test_f1_score       </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.7198559641838074     </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">         test_loss         </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.5192237496376038     </span>│\n",
       "└───────────────────────────┴───────────────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1m       Test metric       \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      DataLoader 0       \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│\u001b[36m \u001b[0m\u001b[36m      test_accuracy      \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.7198559641838074    \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m      test_f1_score      \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.7198559641838074    \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m        test_loss        \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.5192237496376038    \u001b[0m\u001b[35m \u001b[0m│\n",
       "└───────────────────────────┴───────────────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2024</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">03</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">06</span> <span style=\"color: #00ff00; text-decoration-color: #00ff00; font-weight: bold\">14:38:46</span>,<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">310</span> - <span style=\"font-weight: bold\">{</span>pytorch_tabular.tabular_model:<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1533</span><span style=\"font-weight: bold\">}</span> - WARNING - Directory is not empty. Overwriting the \n",
       "contents.                                                                                                          \n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;36m2024\u001b[0m-\u001b[1;36m03\u001b[0m-\u001b[1;36m06\u001b[0m \u001b[1;92m14:38:46\u001b[0m,\u001b[1;36m310\u001b[0m - \u001b[1m{\u001b[0mpytorch_tabular.tabular_model:\u001b[1;36m1533\u001b[0m\u001b[1m}\u001b[0m - WARNING - Directory is not empty. Overwriting the \n",
       "contents.                                                                                                          \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "result = tabular_model.evaluate(test)\n",
    "# pred_df = tabular_model.predict(test)\n",
    "tabular_model.save_model(f\"{trainer_config.checkpoints_path}/{target_col}\") # save in the dir\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pred_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extractSubmision(input_df:pd.DataFrame,\n",
    "                     pred_col: str,\n",
    "                     cm_key='customer',\n",
    "                     mct_key='merchant',\n",
    "                     output_path='submission.csv')->None:\n",
    "    '''\n",
    "    function that extracts the submission file for the AMEX Singapore Hackathon 2024\n",
    "\n",
    "    input_df : pandas Dataframe which has customer, merchant and pred_col\n",
    "    pred_col : name of your prediction score variable\n",
    "    cm_key : customer unique ID (do not change)\n",
    "    mct_key : merchant unique ID (do not change)\n",
    "    output_path : path to save the submission file\n",
    "\n",
    "    Returns - None\n",
    "    '''\n",
    "    print('formate prodiction')\n",
    "    LEN=len(input_df)\n",
    "    if LEN!=12604600:\n",
    "        raise f\"miss matchlenth {LEN} \"\n",
    "    output_df=pd.DataFrame()\n",
    "    output_df[[cm_key,mct_key,'predicted_score']]=input_df[[cm_key,mct_key,pred_col]].apply(pd.to_numeric,errors='coerce')\n",
    "    output_df.to_csv(output_path,index=False)\n",
    "    return None\n",
    "\n",
    "def calc(rec:int,act:int):\n",
    "    crit=rec*2+act\n",
    "    match crit:\n",
    "        case 3: # TT\n",
    "            return 3\n",
    "        case 0: # NN\n",
    "            return 2\n",
    "        case 2: # TN\n",
    "            return 1\n",
    "        case 1: # NT\n",
    "            return 0\n",
    "    return None\n",
    "        \n",
    "# add colum pre_score by func calc eat 'ind_recommended' and 'activaton'\n",
    "        \n",
    "def loadmodel_and_predict(modelpath:str,test_data:pd.DataFrame,data_preprocess:Callable = None) -> pd.DataFrame:\n",
    "    print(f\"loading model at {modelpath}\")\n",
    "    loadedmodel=TabularModel.load_model(modelpath)\n",
    "    # idf=pd.read_csv(test_path)\n",
    "    if data_preprocess:\n",
    "        test_data=data_preprocess(test_data)\n",
    "    print(f\"predicting\")\n",
    "    return loadedmodel.predict(test_data)['prediction']\n",
    "\n",
    "def gen_submission(pred_df:pd.DataFrame):\n",
    "    print(\"generating_pred_score\")\n",
    "    for pred in [\"ind_recommended\",\"activation\",'customer','merchant']:\n",
    "        if pred not in pred_df.columns:\n",
    "            print(f\"missing col {pred}\")\n",
    "\n",
    "\n",
    "    pred_df['predicted_score']=pred_df.apply(lambda x:calc(x['ind_recommended'],x['activation']),axis=1)\n",
    "\n",
    "    extractSubmision(pred_df,'predicted_score')\n",
    "    return None\n",
    "\n",
    "def preprocess(idf: pd.DataFrame):\n",
    "    cols=[]\n",
    "    for col in idf.columns:\n",
    "        if (col not in cat_col_names) and (col not in num_col_names):\n",
    "            cols.append(col)\n",
    "    idf.drop(columns=cols)\n",
    "    return idf\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>distance_05</th>\n",
       "      <th>customer_digital_activity_04</th>\n",
       "      <th>customer_spend_01</th>\n",
       "      <th>customer_industry_spend_01</th>\n",
       "      <th>customer_industry_spend_02</th>\n",
       "      <th>customer_industry_spend_03</th>\n",
       "      <th>customer_industry_spend_04</th>\n",
       "      <th>customer_industry_spend_05</th>\n",
       "      <th>customer_spend_02</th>\n",
       "      <th>customer_spend_03</th>\n",
       "      <th>...</th>\n",
       "      <th>merchant_profile_02</th>\n",
       "      <th>merchant_spend_09</th>\n",
       "      <th>merchant_profile_03</th>\n",
       "      <th>customer_digital_activity_01</th>\n",
       "      <th>merchant_spend_10</th>\n",
       "      <th>customer_profile_03</th>\n",
       "      <th>customer_digital_activity_02</th>\n",
       "      <th>customer_profile_04</th>\n",
       "      <th>customer</th>\n",
       "      <th>merchant</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.621171</td>\n",
       "      <td>NaN</td>\n",
       "      <td>112.3340</td>\n",
       "      <td>80.5525</td>\n",
       "      <td>9.0</td>\n",
       "      <td>966.63</td>\n",
       "      <td>12.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>41.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.437500</td>\n",
       "      <td>26299.0</td>\n",
       "      <td>4777.0</td>\n",
       "      <td>0.8</td>\n",
       "      <td>33.30</td>\n",
       "      <td>72.268283</td>\n",
       "      <td>7.0</td>\n",
       "      <td>423.0</td>\n",
       "      <td>467915</td>\n",
       "      <td>599167</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2.441944</td>\n",
       "      <td>NaN</td>\n",
       "      <td>112.3340</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.0</td>\n",
       "      <td>41.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.397059</td>\n",
       "      <td>7122.0</td>\n",
       "      <td>4803.0</td>\n",
       "      <td>0.8</td>\n",
       "      <td>793.29</td>\n",
       "      <td>72.268283</td>\n",
       "      <td>7.0</td>\n",
       "      <td>423.0</td>\n",
       "      <td>467915</td>\n",
       "      <td>686617</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2.438082</td>\n",
       "      <td>NaN</td>\n",
       "      <td>112.3340</td>\n",
       "      <td>71.1925</td>\n",
       "      <td>3.0</td>\n",
       "      <td>284.77</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>41.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>7222.0</td>\n",
       "      <td>14860.0</td>\n",
       "      <td>0.8</td>\n",
       "      <td>100.00</td>\n",
       "      <td>72.268283</td>\n",
       "      <td>7.0</td>\n",
       "      <td>423.0</td>\n",
       "      <td>467915</td>\n",
       "      <td>829193</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2.072182</td>\n",
       "      <td>NaN</td>\n",
       "      <td>112.3340</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.0</td>\n",
       "      <td>41.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.142857</td>\n",
       "      <td>11410.0</td>\n",
       "      <td>11968.0</td>\n",
       "      <td>0.8</td>\n",
       "      <td>252.38</td>\n",
       "      <td>72.268283</td>\n",
       "      <td>7.0</td>\n",
       "      <td>423.0</td>\n",
       "      <td>467915</td>\n",
       "      <td>1077034</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2.380853</td>\n",
       "      <td>NaN</td>\n",
       "      <td>302.7925</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.0</td>\n",
       "      <td>37.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.100000</td>\n",
       "      <td>1847.0</td>\n",
       "      <td>5842.0</td>\n",
       "      <td>0.8</td>\n",
       "      <td>87.50</td>\n",
       "      <td>72.268283</td>\n",
       "      <td>7.0</td>\n",
       "      <td>423.0</td>\n",
       "      <td>467915</td>\n",
       "      <td>876647</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 69 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   distance_05  customer_digital_activity_04  customer_spend_01  \\\n",
       "0     1.621171                           NaN           112.3340   \n",
       "1     2.441944                           NaN           112.3340   \n",
       "2     2.438082                           NaN           112.3340   \n",
       "3     2.072182                           NaN           112.3340   \n",
       "4     2.380853                           NaN           302.7925   \n",
       "\n",
       "   customer_industry_spend_01  customer_industry_spend_02  \\\n",
       "0                     80.5525                         9.0   \n",
       "1                         NaN                         NaN   \n",
       "2                     71.1925                         3.0   \n",
       "3                         NaN                         NaN   \n",
       "4                         NaN                         NaN   \n",
       "\n",
       "   customer_industry_spend_03  customer_industry_spend_04  \\\n",
       "0                      966.63                        12.0   \n",
       "1                         NaN                         NaN   \n",
       "2                      284.77                         4.0   \n",
       "3                         NaN                         NaN   \n",
       "4                         NaN                         NaN   \n",
       "\n",
       "   customer_industry_spend_05  customer_spend_02  customer_spend_03  ...  \\\n",
       "0                        10.0                4.0               41.0  ...   \n",
       "1                         NaN                4.0               41.0  ...   \n",
       "2                         4.0                4.0               41.0  ...   \n",
       "3                         NaN                4.0               41.0  ...   \n",
       "4                         NaN                3.0               37.0  ...   \n",
       "\n",
       "   merchant_profile_02  merchant_spend_09  merchant_profile_03  \\\n",
       "0             0.437500            26299.0               4777.0   \n",
       "1             0.397059             7122.0               4803.0   \n",
       "2                  NaN             7222.0              14860.0   \n",
       "3             0.142857            11410.0              11968.0   \n",
       "4             0.100000             1847.0               5842.0   \n",
       "\n",
       "   customer_digital_activity_01  merchant_spend_10  customer_profile_03  \\\n",
       "0                           0.8              33.30            72.268283   \n",
       "1                           0.8             793.29            72.268283   \n",
       "2                           0.8             100.00            72.268283   \n",
       "3                           0.8             252.38            72.268283   \n",
       "4                           0.8              87.50            72.268283   \n",
       "\n",
       "   customer_digital_activity_02  customer_profile_04  customer  merchant  \n",
       "0                           7.0                423.0    467915    599167  \n",
       "1                           7.0                423.0    467915    686617  \n",
       "2                           7.0                423.0    467915    829193  \n",
       "3                           7.0                423.0    467915   1077034  \n",
       "4                           7.0                423.0    467915    876647  \n",
       "\n",
       "[5 rows x 69 columns]"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "idf=pd.read_csv('data/Amex_ori/Amex Campus Challenge Round 1.csv')\n",
    "idf.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading model at checkpoints/activation\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2024</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">03</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">06</span> <span style=\"color: #00ff00; text-decoration-color: #00ff00; font-weight: bold\">14:53:09</span>,<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">808</span> - <span style=\"font-weight: bold\">{</span>pytorch_tabular.tabular_model:<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">340</span><span style=\"font-weight: bold\">}</span> - INFO - Preparing the Trainer                       \n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;36m2024\u001b[0m-\u001b[1;36m03\u001b[0m-\u001b[1;36m06\u001b[0m \u001b[1;92m14:53:09\u001b[0m,\u001b[1;36m808\u001b[0m - \u001b[1m{\u001b[0mpytorch_tabular.tabular_model:\u001b[1;36m340\u001b[0m\u001b[1m}\u001b[0m - INFO - Preparing the Trainer                       \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Trainer already configured with model summary callbacks: [<class 'pytorch_lightning.callbacks.model_summary.ModelSummary'>]. Skipping setting a default `ModelSummary` callback.\n",
      "GPU available: True (mps), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "predicting\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cb65f2bfc65840078f5be8190398cb7c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading model at checkpoints/ind_recommended\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2024</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">03</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">06</span> <span style=\"color: #00ff00; text-decoration-color: #00ff00; font-weight: bold\">14:55:01</span>,<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">253</span> - <span style=\"font-weight: bold\">{</span>pytorch_tabular.tabular_model:<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">340</span><span style=\"font-weight: bold\">}</span> - INFO - Preparing the Trainer                       \n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;36m2024\u001b[0m-\u001b[1;36m03\u001b[0m-\u001b[1;36m06\u001b[0m \u001b[1;92m14:55:01\u001b[0m,\u001b[1;36m253\u001b[0m - \u001b[1m{\u001b[0mpytorch_tabular.tabular_model:\u001b[1;36m340\u001b[0m\u001b[1m}\u001b[0m - INFO - Preparing the Trainer                       \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Trainer already configured with model summary callbacks: [<class 'pytorch_lightning.callbacks.model_summary.ModelSummary'>]. Skipping setting a default `ModelSummary` callback.\n",
      "GPU available: True (mps), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "predicting\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "557de119e117484299c9032dca6cba5e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "for target in target_cols:\n",
    "    idf[target]=loadmodel_and_predict(f\"{trainer_config.checkpoints_path}/{target}\",idf,preprocess)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "generating_pred_score\n",
      "missing col activate_pred\n",
      "missing col rec_pred\n",
      "formate prodiction\n"
     ]
    }
   ],
   "source": [
    "\n",
    "gen_submission(idf)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = {k: float(v) for k,v in result[0].items()}\n",
    "result[\"mode\"] = \"Normal\"\n",
    "\n",
    "results.append(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Custom Sampler\n",
    "\n",
    "PyTorch Tabular also allows custom batching strategy through Custom Samplers  which comes in handy when working with imbalanced data.\n",
    "\n",
    "Although you can use any sampler, Pytorch Tabular has a few handy utility functions which takes in the target array and implements WeightedRandomSampler using inverse frequency sampling to combat imbalance. This is analogous to preprocessing techniques like Under or OverSampling in traditional ML systems."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tabular_model = TabularModel(\n",
    "    data_config=data_config,\n",
    "    model_config=model_config,\n",
    "    optimizer_config=optimizer_config,\n",
    "    trainer_config=trainer_config,\n",
    "    verbose=False\n",
    ")\n",
    "sampler = get_balanced_sampler(train[target_col].values.ravel())\n",
    "\n",
    "tabular_model.fit(train=train, validation=val, train_sampler=sampler)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = tabular_model.evaluate(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = {k: float(v) for k,v in result[0].items()}\n",
    "result[\"mode\"] = \"Balanced Sampler\"\n",
    "\n",
    "results.append(result)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Custom Weighted Loss\n",
    "\n",
    "If Samplers were like Over/Under Sampling, Custom Weighted Loss is similar to `class_weights`. Depending on the problem, one of these might help you with imbalance. You can easily make calculate the class_weights and provide them to the CrossEntropyLoss using the parameter `weight`. To make this easier, PyTorch Tabular has a handy utility method which calculates smoothed class weights and initializes a weighted loss. Once you have that loss, it's just a matter of passing it to the 1fit1 method using the `loss` parameter."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tabular_model = TabularModel(\n",
    "    data_config=data_config,\n",
    "    model_config=model_config,\n",
    "    optimizer_config=optimizer_config,\n",
    "    trainer_config=trainer_config,\n",
    "    verbose=False\n",
    ")\n",
    "weighted_loss = get_class_weighted_cross_entropy(train[\"target\"].values.ravel(), mu=0.1)\n",
    "\n",
    "tabular_model.fit(train=train, validation=val, loss=weighted_loss)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = tabular_model.evaluate(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = {k: float(v) for k,v in result[0].items()}\n",
    "result[\"mode\"] = \"Class Weights\"\n",
    "\n",
    "results.append(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res_df = pd.DataFrame(results).T\n",
    "res_df.columns = res_df.iloc[-1]\n",
    "res_df = res_df.iloc[:-1].astype(float)\n",
    "res_df.style.highlight_min(color=\"lightgreen\",axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
